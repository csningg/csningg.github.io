

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="zningg">
  <meta name="keywords" content="">
  
    <meta name="description" content="VSAG: An Optimized Search Framework for Graph-based Approximate Nearest Neighbor Search VSAG 是对现有图算法（Graph-based ANNS）的一套全方位工业级优化方案。本文是对这篇论文的解读与思考！">
<meta property="og:type" content="article">
<meta property="og:title" content="VSAG框架概述">
<meta property="og:url" content="https://csningg.github.io/posts/3838167042/index.html">
<meta property="og:site_name" content="ning">
<meta property="og:description" content="VSAG: An Optimized Search Framework for Graph-based Approximate Nearest Neighbor Search VSAG 是对现有图算法（Graph-based ANNS）的一套全方位工业级优化方案。本文是对这篇论文的解读与思考！">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://csningg.github.io/pictures/20250523/11.25/Untitled/dff374c348_indexing-in-vector-database.png">
<meta property="article:published_time" content="2025-11-24T12:30:47.000Z">
<meta property="article:modified_time" content="2025-11-25T04:27:10.798Z">
<meta property="article:author" content="zningg">
<meta property="article:tag" content="向量检索">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://csningg.github.io/pictures/20250523/11.25/Untitled/dff374c348_indexing-in-vector-database.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>VSAG框架概述 - ning</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/css/macpanel.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"csningg.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":"https://csningg.github.io/"}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong class="navbar-title">Zning</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/" target="_self">
                <i class="iconfont icon-link-fill"></i>
                <span>友链</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="VSAG框架概述"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-11-24 20:30" pubdate>
          2025年11月24日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          8.9k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          74 分钟
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> 次
        </span>
        

      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">VSAG框架概述</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="vsag-an-optimized-search-framework-for-graph-based-approximate-nearest-neighbor-search">VSAG: An Optimized Search Framework for Graph-based Approximate Nearest Neighbor Search</h1>
<p>VSAG 是对现有图算法（Graph-based ANNS）的一套<strong>全方位工业级优化方案</strong>。本文是对这篇论文的解读与思考！ <span id="more"></span></p>
<p><a target="_blank" rel="noopener" href="https://www.vldb.org/pvldb/vol18/p5017-cheng.pdf">论文</a>介绍了一个名为 <strong>VSAG (Vector Search Algorithm Graph)</strong> 的开源框架，由蚂蚁集团（Ant Group）开发 。核心目标是解决当前主流的基于图的近似最近邻搜索（ANNS）算法（如 HNSW）在<strong>生产环境</strong>中面临的性能瓶颈。尽管 HNSW 等基于图的算法在召回率和性能上表现优异，但在大规模生产环境中存在三大痛点：</p>
<ol type="1">
<li><strong>随机内存访问导致的高延迟：</strong> 图遍历需要在内存中随机跳转，导致 CPU 的 L3 缓存未命中率（Cache Miss Rate）极高，严重拖慢速度。</li>
<li><strong>距离计算开销大：</strong> 高维向量的距离计算非常消耗 CPU 资源。</li>
<li><strong>调参成本过高：</strong> 图索引对参数（如最大度数、候选集大小）非常敏感。传统调参需要反复重建索引，耗时极长（可能需要数天），导致很多系统只能使用次优参数。</li>
</ol>
<p>针对以上三个问题，论文依次提出了解决方案。</p>
<h2 id="三大设计优化">三大设计优化</h2>
<h3 id="内存访问优化">内存访问优化</h3>
<p>这是 VSAG 最底层的创新，旨在让“随机”的图搜索变得对 CPU 缓存更友好，实现方式是两点：</p>
<ul>
<li><p><strong>确定性访问贪婪搜索 (Deterministic Access Greedy Search)：</strong> 传统的贪婪搜索是串行的（计算一个-&gt;取下一个）。VSAG 将其改为<strong>批量处理</strong>，对邻居节点进行分组，并利用软件预取（Software Prefetching）技术，在计算当前节点距离时，提前将下一个节点的数据加载到缓存中。</p></li>
<li><p><strong>部分冗余存储 (PRS - Partial Redundant Storage)：</strong> VSAG 设计了一种特殊的存储结构。它不仅存储节点本身，还将该节点的<strong>压缩后的邻居向量</strong>直接冗余存储在节点旁边。</p>
<ul>
<li><strong>作用：</strong> 这样一来，访问某个节点的邻居时，内存访问就从“随机跳转”变成了“顺序读取”。这激活了 CPU 的 <strong>硬件预取（Hardware Prefetching）</strong> 机制，极大降低了缓存未命中率。</li>
<li><strong>平衡：</strong> 引入了参数 <span class="math inline"><em>δ</em></span>（冗余比率）来平衡内存占用和 CPU 效率。<span class="math inline"><em>δ</em> = 1</span>时全冗余（速度最快，费内存），<span class="math inline"><em>δ</em> = 0</span> 时无冗余（省内存）</li>
</ul></li>
</ul>
<h3 id="自动参数调优">自动参数调优</h3>
<p>VSAG 不需要用户手动痛苦地调参，也不需要为了调参反复重建索引。</p>
<ul>
<li><strong>基于“掩码/标签”的索引压缩技术：</strong> VSAG 先用较宽松的参数构建一个“大索引”，并在每条边上打上标签（Label），标记这条边在不同参数下是否应该存在。</li>
<li><strong>免重建调优：</strong> 在调优或搜索时，只需根据标签过滤边，就能模拟出不同参数构建的索引效果。这使得<strong>索引级参数（Index-level Parameters）</strong> 的调优时间从“数天”缩短为“几乎即时” 。</li>
<li><strong>查询级自适应：</strong> 使用决策树模型判断查询的难易程度，动态调整搜索时的候选集大小（<span class="math inline"><em>e</em><em>f</em><sub><em>s</em></sub></span>）。简单的查询少搜点，复杂的查询多搜点。</li>
</ul>
<h3 id="距离计算加速">距离计算加速</h3>
<ul>
<li><strong>标量量化 (Scalar Quantization, SQ) + SIMD：</strong> 将浮点向量压缩（如 SQ4/SQ8），利用 AVX-512 指令集并行计算，大幅减少计算量。</li>
<li><strong>距离分解 (Distance Decomposition)：</strong> 预先计算向量的模长（Norm）并缓存，将欧氏距离计算简化为内积运算，减少实时计算指令。</li>
<li><strong>选择性重排序 (Selective Re-rank)：</strong> 先用低精度（量化后）向量快速筛选出一批候选者，再对其中极少部分进行高精度重算，兼顾了速度和准确率。</li>
</ul>
<h2 id="整体流程">整体流程</h2>
<figure>
<img src="../pictures/20250523/11.25/Untitled/image.png" srcset="/img/loading.gif" lazyload alt="" /><figcaption>image.png</figcaption>
</figure>
<p>Figure 1 展示了 <strong>VSAG（Vector Search Algorithm Graph）</strong> 的整个搜索框架流程。它将整个搜索过程分为了三个主要阶段：<strong>存储（Partial Redundant Storage）</strong>、<strong>搜索执行（Deterministic Access Greedy Search）</strong> 和 <strong>结果优化（Selective Re-rank）</strong>，同时贯穿了自动参数调优。</p>
<p>以下是对这张图的<strong>分步详细解释</strong>：</p>
<p><strong>第一步：部分冗余存储</strong></p>
<p>这是 VSAG 的数据存储基础，旨在优化内存访问效率。</p>
<ul>
<li><strong>混合存储结构 (Redundant vs. Flat):</strong> 图中展示了两种存储状态。
<ul>
<li><strong>Original Vector (蓝色):</strong> 存储原始的高精度向量数据。</li>
<li><strong>Redundant Neighbors (绿色):</strong> 这是核心设计。VSAG 将某个节点的<strong>邻居向量</strong>（压缩后的）直接冗余存储在该节点旁边。</li>
<li><strong><span class="math inline"><em>δ</em> = 0.5</span> (Redundancy Ratio):</strong> 这是一个调节参数。图中 <span class="math inline"><em>δ</em> = 0.5</span>表示只有 50% 的数据采用了冗余存储（Redundant Storage），剩下的 50% 采用普通存储（Flat Storage)。这是一种在“内存占用”和“计算速度”之间取得平衡的机制。</li>
</ul></li>
<li><strong>Code Layout (数据布局):</strong> 放大镜展示了邻居节点具体存了什么：
<ul>
<li><strong>Quantized Code:</strong> 量化后的低精度向量代码（例如 4-bit 量化），用于快速计算。</li>
<li><strong>Id:</strong> 邻居的 ID。</li>
<li><strong>Norm:</strong> 预先计算好的向量模长，用于加速距离计算（距离分解技术）。</li>
<li><strong>Metric Transform:</strong> 距离变换逻辑。</li>
</ul></li>
</ul>
<p><strong>第二步：确定性访问贪婪搜索</strong></p>
<p>这是搜索执行的核心阶段，主要解决图搜索中“内存随机访问”导致的 Cache Miss 问题。</p>
<ul>
<li><strong>Async Prefetch During Computing (计算时异步预取):</strong> 顶部的框图展示了流水线工作模式。当 CPU 正在计算当前向量的量化代码（Q Code Computing）时，利用空闲带宽同时<strong>预取（Prefetching）</strong> 下一批需要的数据到缓存中。</li>
<li><strong>Only Prefetch Valid Neighbors (只预取有效邻居):</strong> 中间的 <span class="math inline"><em>x</em><sub>1</sub></span>到 <span class="math inline"><em>x</em><sub>10</sub></span> 序列展示了过滤逻辑。算法会先剔除掉那些已经访问过的或者被剪枝的邻居（图中 <span class="math inline"><em>x</em><sub>2</sub>, <em>x</em><sub>3</sub></span>被跳过），只对有效的邻居进行预取和计算。</li>
<li><strong>Stride Prefetch (步长预取):</strong> 底部的箭头（例如从 <span class="math inline"><em>x</em><sub>1</sub></span>指向 <span class="math inline"><em>x</em><sub>6</sub></span>）展示了步长预取策略。为了防止数据还没加载进缓存 CPU 就要用，VSAG 会“看得很远”。例如，在计算 <span class="math inline"><em>x</em><sub>1</sub></span> 的距离时，它发出的指令是预取 <span class="math inline"><em>x</em><sub>6</sub></span> 的数据（步长为 5），从而掩盖内存延迟。</li>
</ul>
<p><strong>第三步：选择性重排序</strong></p>
<p>这一步是为了弥补第二步中使用“低精度量化向量”带来的精度损失。</p>
<ul>
<li><strong>Result Push Heap (结果入堆):</strong> 第二步计算出的邻居节点会被推入一个结果堆中。</li>
<li><strong>Low vs. High Precision:</strong>
<ul>
<li>在搜索过程中使用低精度（Quantized Code）快速筛选。</li>
<li>只有通过筛选的少量优质候选项，才会回读原始向量（Original Vector）进行高精度距离计算（即 Re-rank），确保最终结果准确。</li>
</ul></li>
<li><strong>Pop Heap and Visit:</strong> 底部蓝色的长箭头表示循环。从堆中弹出当前最近的节点，回到左侧 PRS 读取它的邻居，开始下一轮搜索 。</li>
</ul>
<p><strong>第四步：自动参数调优</strong></p>
<p>在整个框架运行过程中，有一个自动调优器在持续工作。</p>
<ul>
<li><strong>三层参数 (Environment/Query/Index):</strong> 图例展示了 VSAG 针对三个层级的参数进行自动化管理
<ul>
<li><strong>Index-level:</strong> 如图的最大度数，通过“掩码”技术在不重建索引的情况下动态调整。</li>
<li><strong>Query-level:</strong> 如搜索时的候选集大小 (<span class="math inline"><em>e</em><em>f</em><sub><em>s</em></sub></span>)，根据查询难度动态调整。</li>
<li><strong>Environment-level:</strong> 如预取步长 (<span class="math inline"><em>ω</em></span>)，根据硬件环境自动调整。</li>
</ul></li>
</ul>
<p>VSAG 不是一种全新的图算法结构，而是一个针对图算法的“生产级加速器”。它保留了图算法（如 HNSW）的高召回率特性，但通过魔改内存布局（PRS）解决了“缓存未命中”这一最大的性能杀手，并通过标签化索引解决了“调参难”的运维痛点。对于需要大规模部署向量数据库的企业来说，VSAG 是比原生 HNSWlib 更高效、更可控的选择。</p>
<h2 id="优化细节">优化细节</h2>
<h3 id="内存优化">内存优化</h3>
<p>基于图的向量搜索由于存在随机内存访问模式，导致cache miss的概率较大。内存方案优化是解决cache miss问题，提出3点优化。</p>
<ul>
<li>利用<strong>软件预取</strong>提高缓存命中率（传统的图搜索模式也存在软件预取技术，VASG通过工程手段强化了软件预取技术）</li>
<li>优化<strong>搜索模式</strong>用于增强软件预取技术</li>
<li>优化索引的<strong>内存布局</strong>以高效利用软件预取</li>
</ul>
<p><strong>预取技术</strong></p>
<figure>
<img src="../pictures/20250523/11.25/Untitled/image%201.png" srcset="/img/loading.gif" lazyload alt="" /><figcaption>image.png</figcaption>
</figure>
<p>Figure 2 直观地展示了 VSAG 如何利用 <strong>软件预取</strong>（Software-based Prefetch)技术，将传统的“串行等待”内存访问模式优化为“并行流水线”模式，从而显著减少 CPU 的空转等待时间。</p>
<p>以下是详细的分步解释：</p>
<p><strong>图例说明</strong></p>
<ul>
<li><strong>橙色方块 (Fetch - Sync Operation):</strong> 代表<strong>同步的内存读取</strong>。在基准算法中，当 CPU 需要某个向量数据但缓存中没有时（Cache Miss），必须停下来等待数据从内存加载完毕，这会阻塞后续操作 。</li>
<li><strong>蓝色方块 (<span class="math inline"><em>τ</em>(<em>x</em>, <em>x</em><sub><em>q</em></sub>)</span> - Sync Operation):</strong> 代表<strong>同步的计算操作</strong>。这里指计算向量 <span class="math inline"><em>x</em></span>与查询向量 <span class="math inline"><em>x</em><sub><em>q</em></sub></span> 之间的距离（如欧氏距离)。</li>
<li><strong>绿色方块 (Prefetch - Async Operation):</strong> 代表<strong>异步的预取指令</strong>。这是 VSAG 引入的关键优化。它是一条告诉 CPU “提前把数据从内存拉到缓存”的指令，它在后台运行，<strong>不会阻塞</strong>当前的计算任务。</li>
</ul>
<p><strong>1. Baselines</strong></p>
<p>这是现有普通图搜索算法（如未优化的 HNSW）的执行流程：</p>
<ul>
<li><strong>模式：</strong> Fetch <span class="math inline">→</span> Compute <span class="math inline">→</span> Fetch <span class="math inline">→</span> Compute。</li>
<li><strong>过程：</strong>
<ol type="1">
<li>先花时间取 <span class="math inline"><em>x</em><sub>1</sub></span> 的数据（橙色 Fetch）。</li>
<li>数据到了才能算 <span class="math inline"><em>x</em><sub>1</sub></span>的距离（蓝色 <span class="math inline"><em>τ</em></span>）。</li>
<li>算完后，再去花时间取 <span class="math inline"><em>x</em><sub>2</sub></span> 的数据（橙色 Fetch）。</li>
<li>数据到了再算 <span class="math inline"><em>x</em><sub>2</sub></span> 的距离…</li>
</ol></li>
<li><strong>缺陷：</strong> 这种串行模式导致 CPU 频繁陷入等待。每当处理一个新邻居节点，CPU 都要停下来等内存数据（即图中橙色方块占用的时间），导致了大量的时间浪费。</li>
</ul>
<p><strong>2. VSAG 的优化方案</strong></p>
<p>这是 VSAG 采用软件预取后的执行流程，核心在于<strong>将“取数据”的时间重叠在“算数据”的时间里</strong>：</p>
<ul>
<li><strong><span class="math inline"><em>t</em><sub>1</sub></span> (初始加载):</strong> 处理第一个节点 <span class="math inline"><em>x</em><sub>1</sub></span> 时，不可避免地需要先从内存获取数据（Fetch）。</li>
<li><strong><span class="math inline"><em>t</em><sub>2</sub></span> (并行流水线 - 关键点):</strong>
<ul>
<li>CPU 开始计算 <span class="math inline"><em>x</em><sub>1</sub></span> 的距离（蓝色块）。</li>
<li><strong>与此同时</strong>，VSAG 发出了一条异步指令 <code>Prefetch x2</code>（绿色块），让内存控制器在后台去加载下一个节点 <span class="math inline"><em>x</em><sub>2</sub></span> 的数据 。</li>
<li>因为预取是异步的，它没有打断 <span class="math inline"><em>x</em><sub>1</sub></span> 的计算，两者并行发生。</li>
</ul></li>
<li><strong><span class="math inline"><em>t</em><sub>3</sub></span> (无缝衔接):</strong>
<ul>
<li>当 CPU 准备处理 <span class="math inline"><em>x</em><sub>2</sub></span> 时，由于在 <span class="math inline"><em>t</em><sub>2</sub></span> 阶段已经提前发出了预取请求，<span class="math inline"><em>x</em><sub>2</sub></span> 的数据此时已经加载到了 L3 缓存中 。</li>
<li>因此，CPU <strong>不需要</strong>像 Baseline 那样执行橙色的 <code>Fetch</code> 等待，而是直接开始计算 x_2 的距离。</li>
<li>同时，利用计算 <span class="math inline"><em>x</em><sub>2</sub></span> 的这段时间，再次预取下一个节点 <span class="math inline"><em>x</em><sub>3</sub></span>。</li>
</ul></li>
<li><strong><span class="math inline"><em>t</em><sub>4</sub></span>:</strong> 同样，<span class="math inline"><em>x</em><sub>3</sub></span> 的数据也已就绪，直接进行计算。</li>
</ul>
<p><strong>结论:</strong></p>
<p>通过这种“吃着碗里的（计算当前），看着锅里的（预取下一个）”的策略，VSAG 成功消除了 <span class="math inline"><em>x</em><sub>2</sub></span> 和 <span class="math inline"><em>x</em><sub>3</sub></span> 的内存读取等待时间。</p>
<ul>
<li><strong>效果：</strong> 如右下角所示，原本 Baseline 需要 6 个时间片（<span class="math inline"><em>t</em><sub>1</sub></span> 到 <span class="math inline"><em>t</em><sub>6</sub></span>）才能完成的任务，VSAG 仅用了 4 个时间片（<span class="math inline"><em>t</em><sub>1</sub></span> 到 <span class="math inline"><em>t</em><sub>4</sub></span>）就完成了，节省了 <span class="math inline"><em>t</em><sub>5</sub></span> 和 <span class="math inline"><em>t</em><sub>6</sub></span> 。</li>
<li>这解释了为什么 VSAG 能大幅降低 L3 Cache Miss Rate 并提升 QPS。</li>
</ul>
<h3 id="确定性贪婪访问">确定性贪婪访问</h3>
<figure>
<img src="../pictures/20250523/11.25/Untitled/image%202.png" srcset="/img/loading.gif" lazyload alt="" /><figcaption>image.png</figcaption>
</figure>
<p>软件预取有一定的局限性，比如在图 3(a) 中，<span class="math inline"><em>x</em><sub>2</sub></span> 和 <span class="math inline"><em>x</em><sub>3</sub></span> 已经被访问过，不需要重新计算距离。这使得对这些向量的预取变得无效。此外，在计算 <span class="math inline"><em>x</em><sub>4</sub></span> 时，由于预取间隔太短，预取也可能会失败。</p>
<h4 id="确定性访问">确定性访问</h4>
<p>VSAG 只预取那些尚未被访问过的边。该机制首先批量处理所有邻居节点以确定它们的访问状态。随后，未被访问的邻居被逻辑分组，并进行<strong>集体预取</strong>。这种战略性方法确保了每个预取的内存地址仅对应于计算必需的数据，从而提高了预取效率，并最大程度地减少了冗余内存操作。</p>
<h4 id="步长预取">步长预取</h4>
<p>批量处理确保了每次预取的数据都供未来使用。然而，由于预取的异步性质以及缺乏确认预取完成的回调机制，预取的有效性各不相同。最佳性能发生在所需数据正好在计算流要求时驻留在缓存中。过早预取有被缓存驱逐的风险，而延迟预取则会抵消性能增益。这需要平衡预取时机和计算持续时间。为了解决这个问题，步长预取动态地将硬件计算吞吐量与软件预取速率对齐，从而最大化预取效用。关键参数，预取步长 <span class="math inline"><em>ω</em></span>，决定了在每次预取前发生多少个计算步骤。调整 <span class="math inline"><em>ω</em></span> 至关重要，在后续，我们提出了一个自动选择其最优值的策略。</p>
<p>如图 3(b) 所示，调整后的模式表明在批量处理期间，确定性访问策略消除了访问 <span class="math inline"><em>x</em><sub>2</sub></span> 和 <span class="math inline"><em>x</em><sub>3</sub></span> 的需要。因此，搜索逻辑从 <span class="math inline"><em>x</em><sub>1</sub></span> 直接推进到 <span class="math inline"><em>x</em><sub>4</sub></span>。这种序列修改使得预取机制能够在计算 <span class="math inline"><em>x</em><sub>1</sub></span> 时瞄准 <span class="math inline"><em>x</em><sub>4</sub></span>。图 3(c) 进一步揭示了异步预取的时间特性：数据加载过程需要两个向量计算周期才能填充缓存行。当 <span class="math inline"><em>x</em><sub>1</sub></span> 的计算开始时，只能预取 <span class="math inline"><em>x</em><sub>4</sub></span> 向量。在 <span class="math inline"><em>x</em><sub>1</sub></span> 和 <span class="math inline"><em>x</em><sub>4</sub></span> 的计算之后，步长预取策略确保了 <span class="math inline"><em>x</em><sub>6</sub></span> 数据的及时缓存填充，这些数据可立即用于后续计算。</p>
<h3 id="确定性贪婪访问伪码">确定性贪婪访问伪码</h3>
<figure>
<img src="../pictures/20250523/11.25/Untitled/image%203.png" srcset="/img/loading.gif" lazyload alt="" /><figcaption>image.png</figcaption>
</figure>
<p>从表面上看，这段代码与标准的基于图的近似最近邻搜索（如 HNSW）中的贪婪搜索逻辑非常相似。<strong>然而，VSAG 的全部性能提升和设计优势，都隐藏在算法中关键操作的底层实现细节中。</strong></p>
<p><strong>1. 算法概述与标准流程</strong> 该算法描述了在 VSAG 构建的图索引 (<span class="math inline"><em>G</em></span>) 上，从一个入口点开始搜索，最终找到最接近查询向量 (<span class="math inline"><em>q</em></span>) 的 L 个候选者（即 <span class="math inline"><em>e</em><em>f</em><sub><em>s</em></sub></span>）的过程。</p>
<ul>
<li><strong>初始化（Lines 1-3）：</strong> 从预先确定的入口点 <span class="math inline"><em>e</em></span> 开始搜索。将 <span class="math inline"><em>e</em></span> 加入到两个优先级队列：
<ul>
<li><span class="math inline"><em>C</em></span> (Candidate Pool)：最终候选集，大小限制为 L。</li>
<li><span class="math inline"><em>W</em></span> (Working Queue)：待探索节点集合，用于驱动搜索。</li>
</ul></li>
<li><strong>主循环（Lines 4-14）：</strong> 只要 <span class="math inline"><em>W</em></span> 中还有未探索的节点，就继续循环。</li>
<li><strong>探索（Line 5）：</strong> 从 <span class="math inline"><em>W</em></span> 中取出当前离查询向量 <span class="math inline"><em>q</em></span> 最近的节点 <span class="math inline"><em>x</em><sub><em>c</em></sub></span>。</li>
</ul>
<p><strong>VSAG 核心优化实现（三层加速）</strong> VSAG 的三大优化（内存、计算、调参）都被嵌入在主循环内部（Lines 6-14）的操作中：</p>
<p><strong>优化 A：内存访问加速 (Deterministic Access &amp; PRS)</strong></p>
<p>VSAG 针对图搜索的随机内存访问模式进行了改造，尽管伪代码是线性循环，但底层实现是并行的。</p>
<ul>
<li><strong>邻居获取（Line 6）：</strong> 获取 <span class="math inline"><em>x</em><sub><em>c</em></sub></span> 的所有邻居 <span class="math inline"><em>N</em>(<em>x</em><sub><em>c</em></sub>)</span>。
<ul>
<li><strong>PRS 机制：</strong> 在实际实现中，由于 <strong>PRS（部分冗余存储）</strong> 的内存布局，当程序访问 <span class="math inline"><em>x</em><sub><em>c</em></sub></span> 的数据时，其部分邻居的压缩向量（<span class="math inline"><em>Q</em><sub><em>x</em><sub><em>i</em></sub></sub></span>）已经被 <strong>硬件预取器</strong> 自动加载到 Cache 中了。</li>
</ul></li>
<li><strong>批量处理与预取（Lines 7-14 的实际实现）：</strong>
<ul>
<li>在执行循环前，VSAG 会先将所有<strong>有效</strong>邻居（未访问且未被剪枝）收集成一个批次。</li>
<li>在计算 <span class="math inline"><em>x</em><sub><em>j</em></sub></span> 的距离时，底层实现会利用 <strong>软件预取（Stride Prefetch）</strong> 指令，同时异步加载下一个批次中 <span class="math inline"><em>x</em><sub><em>j</em> + <em>ω</em></sub></span> 的数据。这实现了计算与内存 I/O 的重叠（如图 Figure 2 所示）。</li>
</ul></li>
</ul>
<p><strong>优化 B：计算加速 (Low-Precision Distance)</strong></p>
<p>距离计算是高维搜索中的 CPU 瓶颈。VSAG 在 <strong>Line 10</strong> 的距离计算 <span class="math inline"><em>d</em><sub><em>c</em>, <em>j</em></sub></span> 中应用了加速技术：</p>
<ul>
<li><strong>低精度计算：</strong> 这里的距离计算使用的不是原始的高精度（Float32）向量，而是 <strong>PRS 中存储的低精度量化代码（Quantized Code）</strong>。这极大减少了计算量。</li>
<li><strong>距离分解与 SIMD：</strong> 实际的距离函数还使用了<strong>距离分解</strong>（预先计算 <span class="math inline">||<em>y</em>||<sup>2</sup></span>）来简化欧氏距离的计算，并利用 <strong>SIMD</strong> 指令（如 AVX-512）进行高度并行计算，进一步提高 <span class="math inline"><em>d</em><sub><em>c</em>, <em>j</em></sub></span> 的计算速度。</li>
</ul>
<p><strong>优化 C：自动参数调优 (Self-Tuned Parameters)</strong> 算法中的两个关键参数和判断条件都受到了 VSAG 自动调优机制的动态影响：</p>
<ul>
<li><strong>动态 L（Line 13）：</strong>
<ul>
<li>L 是最终候选集 C 的大小限制（对应于 <span class="math inline"><em>e</em><em>f</em><sub><em>s</em></sub></span> 参数）。在传统算法中这是固定的。</li>
<li>在 VSAG 中，这个参数由 <strong>查询级参数调优 (QLP)</strong> 机制控制。QLP 使用一个 GBDT 决策树模型，根据查询 <span class="math inline"><em>q</em></span> 的难度<strong>动态调整 <span class="math inline"><em>L</em></span> 的值</strong>。简单的查询会设置较小的 <span class="math inline"><em>L</em></span>，困难的查询会设置较大的 L，以平衡召回率和速度。</li>
</ul></li>
<li><strong>动态剪枝条件（Line 8）：</strong>
<ul>
<li><span class="math inline">IsPruned(<em>x</em><sub><em>j</em></sub>)</span> 判断邻居 <span class="math inline"><em>x</em><sub><em>j</em></sub></span> 是否应该被剪枝。</li>
<li>这个判断结合了 <strong>索引级参数调优 (ILP)</strong> 机制。VSAG 在建图时给每条边打了标签，<strong><span class="math inline">IsPruned</span> 函数在运行时根据标签动态过滤边</strong>，模拟不同的索引结构，避免了耗时的索引重建。</li>
</ul></li>
</ul>
<p><strong>总结</strong> 尽管算法 1 的骨架是经典的贪婪搜索，但 VSAG 赋予了其中关键操作全新的、高效的实现：</p>
<table>
<thead>
<tr class="header">
<th><strong>伪代码行数</strong></th>
<th><strong>对应操作</strong></th>
<th><strong>VSAG 的底层优化</strong></th>
<th><strong>目的</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Line 6</td>
<td>获取邻居列表</td>
<td><strong>PRS 内存布局</strong></td>
<td>触发硬件预取，减少 Cache Miss</td>
</tr>
<tr class="even">
<td>Line 8</td>
<td>检查是否剪枝</td>
<td><strong>ILP (索引标签过滤)</strong></td>
<td>动态调优索引参数，无需重建</td>
</tr>
<tr class="odd">
<td>Line 10</td>
<td>计算距离 <span class="math inline"><em>d</em><sub><em>c</em>, <em>j</em></sub></span></td>
<td><strong>量化计算、距离分解、SIMD</strong></td>
<td>降低 CPU 消耗，提速</td>
</tr>
<tr class="even">
<td>Line 13</td>
<td>限制候选集大小 L</td>
<td><strong>QLP (动态 <span class="math inline"><em>e</em><em>f</em><sub><em>s</em></sub></span> 模型)</strong></td>
<td>根据查询难度自适应，平衡性能和精度</td>
</tr>
</tbody>
</table>
<p>VSAG 的性能优势正是来源于这种<strong>系统工程级</strong>的集成优化，将内存访问、计算加速和参数自适应完美地嵌入到了这个基本的图遍历流程中。</p>
<h2 id="部分冗余存储">部分冗余存储</h2>
<p>虽然将精心设计的预取模式整合到搜索过程中理论上可以提高性能，但基于软件的预取的固有局限性阻止了对所有所需向量的内存可用性提供保证。这种现象归因于多个基本限制： - 预取指令仍然是建议性操作而非强制性命令。即使实施了最佳预取模式，它们的实际执行也无法保证。</p>
<ul>
<li>缓存行争用是另一个严峻挑战。在多进程环境中，激进的预取策略可能通过过早的数据加载导致 L3 缓存污染。</li>
<li>预取机制之间固有的成本差异进一步加剧了这些问题。与硬件实现的替代方案相比，基于软件的预取操作成本更高，效率也更低。</li>
</ul>
<p>即<strong>软件预取</strong> 存在三大不足：1. 不可靠（非强制性）。2. 可能导致 缓存污染。3. 效率低于硬件预取。针对这三个问题，我们提出了以下优化</p>
<h3 id="基于硬件的预取">基于硬件的预取</h3>
<p>基于硬件的预取依赖于硬件机制，这些机制自适应地从缓存未命中事件中学习，以预测内存访问模式。系统采用一个训练缓冲区，动态识别重复的数据访问序列，自动将预期数据预取到缓存层次结构中。与软件控制的预取相比，这种硬件方法表现出更好的运行时效率，同时在架构层面透明运行。训练机制对于顺序内存访问模式尤其有效，它可以快速检测和利用顺序内存访问特性。这种优化对于空间分区索引结构，如基于倒排文件（IVF）的索引结构特别有益，因为属于同一分区的向量保持连续的存储分配。相反，基于图的索引架构表现出不规则的访问模式，空间局部性差，导致随机内存访问效率低下。访问序列固有的随机性阻止了训练缓冲区建立有效的模式识别模型。</p>
<h4 id="redundantly-storing-vectors冗余存储向量">Redundantly Storing Vectors（冗余存储向量）</h4>
<p>VSAG 通过冗余向量存储将空间分区索引的优势整合到基于图的索引算法中。通过在每个节点的数据结构中将邻居列表与其对应的向量共同定位，实现了顺序内存访问。这种设计确保了邻居检索操作只需要在连续内存区域内进行顺序访问，从而充分利用了硬件预取能力。</p>
<p>如图 1 所示，考虑 10 个连续存储在内存中的向量。即使在访问 <span class="math inline"><em>x</em><sub>1</sub></span> 到 <span class="math inline"><em>x</em><sub>5</sub></span> 且 <span class="math inline"><em>x</em><sub>2</sub></span> 和 <span class="math inline"><em>x</em><sub>3</sub></span> 不是立即需要的情况下，硬件预取器仍然可以主动将 <span class="math inline"><em>x</em><sub>4</sub></span> 加载到缓存中。这种行为源于将相邻向量（<span class="math inline"><em>x</em><sub>1</sub></span> 到 <span class="math inline"><em>x</em><sub>5</sub></span>）存储在连续内存地址中所创建的内存局部性。一致的内存布局和可预测的访问模式通过硬件优化，有效地弥补了基于软件的预取效率低下的问题。</p>
<h4 id="balance-of-computational-efficiency-and-memory-utilization计算效率与内存利用的平衡">Balance of Computational Efficiency and Memory Utilization（计算效率与内存利用的平衡）</h4>
<p>为了解决工业应用中固定实例规格（例如 4 核 16G，2 核 8G）导致的计算-内存资源不平衡，我们提出了 PRS，以利用硬件预取来减少 CPU 空闲时间。一个可动态调整的冗余比率 <span class="math inline"><em>δ</em></span> 控制了图中冗余存储的邻居向量的比例，平衡了预取效率和 CPU 利用率。当 <span class="math inline"><em>δ</em> = 1</span> 时，完全冗余最大化硬件预取效益，以更高的内存消耗为代价实现峰值 CPU 利用率。相反，当 <span class="math inline"><em>δ</em> = 0</span> 时，消除冗余以最小化内存使用，但牺牲了预取效率。这种灵活性实现了对工作负载感知的资源优化。 <img src="../pictures/20250523/11.25/Untitled/image4.png" srcset="/img/loading.gif" lazyload alt="alt text" /></p>
<p>对于高吞吐量/高召回率场景（图 4 (a)），将 <span class="math inline"><em>δ</em></span> 增加到 1 优先考虑 CPU 效率，以更少的计算资源满足苛刻的目标。在内存受限、吞吐量要求适中的环境（图 4 (b)）中，将 <span class="math inline"><em>δ</em></span> 减少到 0 减轻了内存压力，同时允许实例降配（例如 4 核 16G 降至 2 核 8G），通过受控的计算扩展来保持服务质量并降低基础设施成本。</p>
<p>PRS (Partial Redundant Storage) 是 VSAG 解决内存访问瓶颈的终极策略，它利用 <strong>硬件预取</strong> 的高效率来弥补软件预取的不足。</p>
<p>方法： 通过在每个节点的数据结构中冗余存储邻居的压缩向量（共同定位），在物理内存中创造出顺序访问模式。效益： 这种顺序模式激活了 CPU 的硬件预取器，实现自动、高效地将邻居数据加载到缓存，彻底解决了基于图的 ANNS 算法中随机内存访问效率低下的问题。灵活性： 引入了可动态调整的冗余比率 <span class="math inline"><em>δ</em></span>，允许用户根据实际的硬件配置和业务需求（如高吞吐 vs 内存受限）来灵活平衡内存消耗和计算效率。</p>
<h2 id="距离加速计算">距离加速计算</h2>
<p>最近的研究表明，精确距离计算占据了基于图的 ANNS 算法的大部分时间成本。近似距离技术，例如标量量化（Scalar Quantization），可以加速这一过程，但代价是搜索准确性降低。VSAG 采用两阶段方法：首先执行近似距离搜索，然后进行精确距离重排序（re-ranking）。节分析了距离计算方案，后续章节详细介绍了 VSAG 组件的优化策略。</p>
<h3 id="distance-computation-cost-analysis距离计算成本分析">Distance Computation Cost Analysis（距离计算成本分析）</h3>
<p>VSAG 在图遍历操作期间使用低精度向量，同时将精确距离计算专门保留给最终结果的重排序。这种双精度架构通过精度感知的层次化处理，有效地最小化了距离计算操作（DCO）的开销，同时保持了搜索准确性。</p>
<p>如果我们只考虑距离计算产生的成本，总距离计算成本可以表示为：<br /><span class="math display">总成本 = 低精度成本 + 高精度成本 = 低精度计算次数 ⋅ 单次低精度成本 + 高精度计算次数 ⋅ 单次高精度成本</span><br /></p>
<p><span class="math inline"><em>n</em><sub><em>l</em><em>p</em></sub></span>（低精度计算次数）的优化与具体的算法工作流程密切相关，而 <span class="math inline"><em>t</em><sub><em>h</em><em>p</em></sub></span>（单次高精度成本）主要由 <span class="math inline">FLOAT32</span> 向量操作的计算成本决定——这两者都相对恒定。</p>
<p>因此，VSAG 框架主要侧重于优化参数 <span class="math inline"><strong>t</strong><sub><strong>l</strong><strong>p</strong></sub></span>（单次低精度成本）和 <span class="math inline"><strong>n</strong><sub><strong>h</strong><strong>p</strong></sub></span>（高精度计算次数）。</p>
<p>VSAG 通过三种方式优化总成本： - （优化 <span class="math inline"><strong>t</strong><sub><strong>l</strong><strong>p</strong></sub></span>） 量化技术、硬件指令集 SIMD 和内存高效存储的结合实现了单次低精度距离计算的指数级降低。</p>
<ul>
<li>（优化 <span class="math inline"><strong>n</strong><sub><strong>l</strong><strong>p</strong></sub></span>） 通过参数优化增强量化精度，减轻了精度损失导致的候选集膨胀，实现了所需低精度计算的次线性增长。</li>
<li>（优化 <span class="math inline"><strong>n</strong><sub><strong>h</strong><strong>p</strong></sub></span>） 具有动态阈值的选择性重排序建立了准确性和效率的平衡，将高精度验证限制在对数级规模的候选子集。</li>
</ul>
<h3 id="最小化低精度计算开销">最小化低精度计算开销</h3>
<p>现代 CPU 采用 SIMD 指令集（SSE/AVX/AVX512）通过向量化操作来加速距离计算。这些指令并行处理 128 位、256 位或 512 位数据块，结合向量压缩技术可以同时处理多个向量。例如，AVX512 每条指令可以计算一个 16 维 <span class="math inline">FLOAT32</span> 向量的距离，但当将向量压缩到 128 位时，它通过并行处理四个向量对实现 4 倍加速</p>
<p>乘积量化 (PQ) 通过 SIMD 加载的查找表，为批量处理实现了高压缩比。虽然 PQ-Fast Scan 在基于分区的搜索中通过块式计算表现出色，但由于图基搜索中随机的向量存储模式和无法过滤已访问节点，导致其有效性降低，造成 SIMD 带宽浪费。相比之下，标量量化 (SQ) 通过直接压缩向量维度（例如 <span class="math inline">FLOAT32</span> 降至 <span class="math inline">INT8/INT4</span>）且不需要查找表，被证明更适合图算法。正如 VSAG 所示，SQ 在压缩比和精度保持之间实现了最佳平衡，同时充分利用了 SIMD 加速能力，使其对于内存受限的图遍历尤其有效。</p>
<p><strong>Distance Decomposition（距离分解）</strong></p>
<p>VSAG 通过解耦静态和动态分量来优化欧氏距离计算。系统在数据库索引期间预先计算和缓存不变的向量范数 (<span class="math inline">∥<strong>x</strong><sub><strong>b</strong></sub>∥<sup>2</sup></span>)，然后在查询期间将它们与实时的点积计算结合。这种分解减少了操作复杂性，同时保留了数学上的等价性，如重构的欧氏距离公式所示： <br /><span class="math display">∥<strong>x</strong><sub><strong>b</strong></sub> − <strong>x</strong><sub><strong>q</strong></sub>∥<sup>2</sup> = ∥<strong>x</strong><sub><strong>b</strong></sub>∥<sup>2</sup> + ∥<strong>x</strong><sub><strong>q</strong></sub>∥<sup>2</sup> − 2<strong>x</strong><sub><strong>b</strong></sub> ⋅ <strong>x</strong><sub><strong>q</strong></sub></span><br /></p>
<p>计算优化策略可总结为：在搜索操作期间，只有内积项 <span class="math inline"><strong>x</strong><sub><strong>b</strong></sub> ⋅ <strong>x</strong><sub><strong>q</strong></sub></span> 需要实时计算，而平方查询范数 <span class="math inline">∥<strong>x</strong><sub><strong>q</strong></sub>∥<sup>2</sup></span> 可以在启动搜索过程之前离线预计算。通过为每个数据库向量 <span class="math inline"><strong>x</strong><sub><strong>b</strong></sub></span> 仅存储一个额外的 <span class="math inline">FLOAT32</span> 值（即预计算的 <span class="math inline">∥<strong>x</strong><sub><strong>b</strong></sub>∥<sup>2</sup></span>），我们可以有效地将计算成本高昂的欧氏距离计算转化为等效的内积操作。这种时空权衡减少了距离计算中的减法 CPU 指令，节省了一个 CPU 时钟周期。</p>
<h3 id="selective-re-rank选择性重排序">Selective Re-rank（选择性重排序）</h3>
<p>量化方法可以显著提高检索效率，但量化误差可能导致召回率大幅下降。虽然使用全精度向量进行重排序可以减轻这种性能损失，但对所有候选者进行详尽的重排序效率低下。VSAG 框架通过选择性重排序来应对这一挑战，在不牺牲系统性能的情况下有效地补偿了距离计算中的近似误差。 一种简单的方法是仅选择那些低精度距离较小的候选者进行重排序。然而，需要重排序的最佳候选者数量会根据查询特性、量化误差分布和搜索要求 <span class="math inline"><em>k</em></span> 发生显著变化。为了解决这种动态需求，VSAG 实现了 DDC 方案，该方案可以基于误差-距离相关性分析自动调整重排序范围。</p>
<h3 id="小结">小结</h3>
<p>VSAG 通过 双精度架构 和 三项核心优化 来加速距离计算，目标是最小化 单次低精度成本 (<span class="math inline"><strong>t</strong><sub><strong>l</strong><strong>p</strong></sub></span>) 和 高精度重算次数 (<span class="math inline"><strong>n</strong><sub><strong>h</strong><strong>p</strong></sub></span>)。</p>
<ul>
<li><p>最小化 <span class="math inline"><strong>t</strong><sub><strong>l</strong><strong>p</strong></sub></span> (单次低精度成本)：量化选择： 采用标量量化 (SQ)，因其无查找表的特性，比 PQ 更适合于基于图的随机访问模式。</p></li>
<li><p>硬件加速： 充分利用 SIMD（如 AVX512）指令集的向量化能力，对压缩后的数据进行并行计算。</p></li>
<li><p>距离分解： 将欧氏距离公式重构为 <span class="math inline"><strong>∥</strong><strong>x</strong><sub><strong>b</strong></sub><strong>∥</strong><sup><strong>2</strong></sup> <strong>+</strong> <strong>∥</strong><strong>x</strong><sub><strong>q</strong></sub><strong>∥</strong><sup><strong>2</strong></sup> <strong>−</strong> <strong>2</strong><strong>x</strong><sub><strong>b</strong></sub> <strong>⋅</strong> <strong>x</strong><sub><strong>q</strong></sub></span>。通过预计算 <span class="math inline"><strong>∥</strong><strong>x</strong><sub><strong>b</strong></sub><strong>∥</strong><sup><strong>2</strong></sup></span> 和 <span class="math inline"><strong>∥</strong><strong>x</strong><sub><strong>q</strong></sub><strong>∥</strong><sup><strong>2</strong></sup></span>，将昂贵的欧氏距离计算转化为高效的内积操作，节省 CPU 时钟周期。</p></li>
<li><p>最小化 <span class="math inline"><strong>n</strong><sub><strong>h</strong><strong>p</strong></sub></span> (高精度重算次数)：选择性重排序： 实现了 DDC 方案，根据查询的动态特性和量化误差分布，自动确定需要进行高精度验证的候选集大小。</p></li>
</ul>
<p>这确保了只对最有可能影响最终召回率的少量候选集使用昂贵的高精度计算，从而在精度和效率之间取得最佳平衡。</p>
<h2 id="参数自动寻优">参数自动寻优</h2>
<p>VSAG 的调优策略是分层的，针对不同类型的参数使用了不同的方法，其中一个核心部分就是基于模型的<strong>查询级参数调优（QLP）</strong>。</p>
<p>以下是 VSAG 三层参数调优的详细解释，重点介绍集成的模型：</p>
<h3 id="查询级参数调优-qlp集成了-gbdt-决策树模型">1. 查询级参数调优 (QLP)：集成了 GBDT 决策树模型</h3>
<p>查询级参数（Query-level Parameters, QLP）主要指的是搜索时的<strong>候选集大小 <span class="math inline"><em>e</em><em>f</em><sub><em>s</em></sub></span></strong>（在伪代码中是 <span class="math inline"><em>L</em></span>）。这个参数对查询速度和召回率的影响最大。</p>
<ul>
<li><strong>问题：</strong> 不同的查询向量（Query Vector）搜索难度差异巨大。对简单的查询使用很大的 <span class="math inline"><em>e</em><em>f</em><sub><em>s</em></sub></span> 会浪费时间；对困难的查询使用很小的 <span class="math inline"><em>e</em><em>f</em><sub><em>s</em></sub></span> 会牺牲召回率。</li>
<li><strong>VSAG 的解决方案：</strong> <strong>训练一个轻量级的分类器，实时判断查询的难度，动态调整 <span class="math inline"><em>e</em><em>f</em><sub><em>s</em></sub></span>。</strong></li>
</ul>
<p><strong>模型细节：</strong></p>
<ol type="1">
<li><strong>使用的模型：</strong> <strong>GBDT (Gradient Boosting Decision Tree，梯度提升决策树)。</strong> 论文选择 GBDT 是因为它计算速度快、模型小巧，适合在低延迟的搜索路径中实时推理。</li>
<li><strong>训练目标：</strong> 模型的目标是预测一个查询是“简单”还是“困难”，或者更细致地分为 <span class="math inline"><em>k</em></span> 个难度等级。</li>
<li><strong>特征工程：</strong> 模型使用在搜索初期阶段（前几跳）就能获取到的<strong>局部特征</strong>作为输入，例如：
<ul>
<li><strong>当前候选集的距离分布：</strong> 候选者之间的距离方差、最大最小值。</li>
<li><strong>距离变化率：</strong> 上一轮和本轮最远距离的变化。</li>
<li><strong>节点连通度：</strong> 当前探索的节点的度数等。</li>
</ul></li>
<li><strong>动态调整：</strong>
<ul>
<li>当模型预测当前查询属于“简单”类别时，系统会动态地将 <span class="math inline"><em>e</em><em>f</em><sub><em>s</em></sub></span> 设置为一个较小的值 (<span class="math inline"><em>L</em><sub><em>m</em><em>i</em><em>n</em></sub></span>)，提前结束不必要的探索。</li>
<li>当模型预测为“困难”类别时，系统会增大 <span class="math inline"><em>e</em><em>f</em><sub><em>s</em></sub></span> (<span class="math inline"><em>L</em><sub><em>m</em><em>a</em><em>x</em></sub></span>)，允许算法探索更多的邻居，以确保高召回率。</li>
</ul></li>
</ol>
<h3 id="索引级参数调优-ilp基于标签的免重建技术非模型">2. 索引级参数调优 (ILP)：基于“标签”的免重建技术（非模型）</h3>
<p>索引级参数（Index-level Parameters, ILP）如最大度数 <span class="math inline"><em>M</em></span>、建图时的候选集大小 <span class="math inline"><em>e</em><em>f</em><sub><em>c</em><em>o</em><em>n</em><em>s</em><em>t</em><em>r</em><em>u</em><em>c</em><em>t</em><em>i</em><em>o</em><em>n</em></sub></span> 等。调整这些参数传统上需要<strong>重建整个图索引</strong>。</p>
<ul>
<li><strong>问题：</strong> 重建索引非常耗时（如 GIST1M 需要数十小时）。</li>
<li><strong>VSAG 的解决方案：</strong> <strong>基于“标签”的虚拟索引技术，实现参数调优的“免重建”。</strong></li>
</ul>
<p><strong>技术细节：</strong></p>
<ol type="1">
<li><strong>一次性构建：</strong> VSAG 只用一套<strong>最宽松</strong>的参数（例如最大的 <span class="math inline"><em>M</em></span>）构建一次索引。</li>
<li><strong>边标签（Edge Labeling）：</strong> 在构建过程中，VSAG 不会物理删除那些被剪枝的边。相反，它会给每条边打上一个<strong>标签（Label）</strong>，记录这条边在多严格的剪枝条件下会被保留。</li>
<li><strong>动态过滤：</strong> 在搜索阶段，用户可以动态设置一个<strong>虚拟参数</strong>。系统会根据这个虚拟参数，实时地在图遍历时<strong>过滤掉</strong>那些标签不满足要求的边。</li>
<li><strong>结论：</strong> 这是一种<strong>工程优化</strong>而非机器学习模型，它将原本需要大量时间进行 I/O 操作（重建索引）的调优过程，转化为了极快的<strong>内存内数据过滤</strong>操作。</li>
</ol>
<h3 id="环境级参数调优-elp基于网格搜索非模型">3. 环境级参数调优 (ELP)：基于网格搜索（非模型）</h3>
<p>环境级参数（Environment-level Parameters, ELP）主要与底层硬件和运行环境相关，例如 <strong>软件预取步长 <span class="math inline"><em>ω</em></span></strong>。</p>
<ul>
<li><strong>问题：</strong> 不同的 CPU 架构、缓存大小、内存带宽，其最优的预取步长 <span class="math inline"><em>ω</em></span> 是不同的。</li>
<li><strong>VSAG 的解决方案：</strong> <strong>离线网格搜索（Grid Search）。</strong></li>
</ul>
<p><strong>技术细节：</strong></p>
<ol type="1">
<li><strong>测试：</strong> 在索引构建完毕后，VSAG 在一个预定义的参数网格中，运行少量的测试查询，系统性地尝试 <span class="math inline"><em>ω</em></span> 的不同取值。</li>
<li><strong>评估：</strong> 评估哪个 <span class="math inline"><em>ω</em></span> 值能带来最高的 QPS（即最低的 L3 Cache Miss Rate）。</li>
<li><strong>锁定：</strong> 一旦找到最优的 <span class="math inline"><em>ω</em></span> 值，就将其锁定为当前运行环境的配置参数。</li>
</ol>
<p>这同样是一种<strong>系统配置自动化</strong>的方法，不依赖复杂的机器学习模型，但能确保底层硬件的效率得到最大化。</p>
<h2 id="vsag-测试性能">VSAG 测试性能</h2>
<p>相比于目前工业界标准的 <strong>HNSWlib</strong> 和 Facebook 的 <strong>Faiss</strong>，VSAG 的优势主要体现在以下几个方面：</p>
<p><strong>显著的性能提升 (高达 4 倍 QPS)</strong></p>
<p>在相同的召回率（Recall）下，VSAG 的吞吐量（QPS）显著高于 HNSWlib。</p>
<ul>
<li><strong>数据：</strong> 在 GIST1M 数据集上，同等精度下 VSAG 比 HNSWlib 快 <strong>4倍</strong> 。</li>
<li><strong>原因：</strong> HNSWlib 的 L3 Cache Miss 率通常高达 90% 以上，而 VSAG 通过 PRS 和预取技术将其降低到了 <strong>39%</strong> 左右。</li>
</ul>
<p><strong>“免重建”的参数自适应</strong></p>
<ul>
<li><strong>存量痛点：</strong> 在 HNSWlib 中，如果你想调整图的连通度（M）来优化性能，你必须重新插入所有数据重建索引。</li>
<li><strong>VSAG 优势：</strong> VSAG 可以在不重建索引的情况下，通过“边过滤”动态调整索引结构参数。对于拥有十亿级向量的生产系统，这节省了数小时甚至数天的运维时间。</li>
</ul>
<p><strong>更好的资源利用率平衡</strong></p>
<ul>
<li><strong>存量痛点：</strong> 传统算法通常受限于机器规格（例如 4核16G），经常出现 CPU 跑满但内存空闲，或者内存满了 CPU 却在空转。</li>
<li><strong>VSAG 优势：</strong> 通过 PRS 的冗余比率 <span class="math inline"><em>δ</em></span>，VSAG 可以根据机器的实际硬件（计算型 vs 内存型实例）灵活调整。如果是计算型机器，增加冗余以换取速度；如果是内存受限机器，减少冗余以节省空间。</li>
</ul>
<p><strong>对高维数据的处理更优</strong></p>
<ul>
<li><strong>VSAG 优势：</strong> 针对 OpenAI 等大模型生成的 1536 维 embedding，VSAG 的量化和距离优化表现尤为突出。实验显示在 OpenAI 数据集上，VSAG 提供了比 HNSWlib 高约 400% 的 QPS 16。</li>
</ul>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93/" class="category-chain-item">向量数据库</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E5%90%91%E9%87%8F%E6%A3%80%E7%B4%A2/" class="print-no-link">#向量检索</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>VSAG框架概述</div>
      <div>https://csningg.github.io/posts/3838167042/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>zningg</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年11月24日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/posts/2498300446/" title="标准库的常用算法">
                        <span class="hidden-mobile">标准库的常用算法</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
    <div id="giscus" class="giscus"></div>
    <script type="text/javascript">
      Fluid.utils.loadComments('#giscus', function() {
        var options = {"repo":"csningg/comment","repo-id":"R_kgDOOvyAGA","category":"General","category-id":"DIC_kwDOOvyAGM4Cqinz","theme-light":"light","theme-dark":"dark","mapping":"pathname","reactions-enabled":1,"emit-metadata":0,"input-position":"bottom","lang":"zh-CN"};
        var attributes = {};
        for (let option in options) {
          if (!option.startsWith('theme-')) {
            var key = option.startsWith('data-') ? option : 'data-' + option;
            attributes[key] = options[option];
          }
        }
        var light = 'light';
        var dark = 'dark';
        window.GiscusThemeLight = light;
        window.GiscusThemeDark = dark;
        attributes['data-theme'] = document.documentElement.getAttribute('data-user-color-scheme') === 'dark' ? dark : light;
        for (let attribute in attributes) {
          var value = attributes[attribute];
          if (value === undefined || value === null || value === '') {
            delete attributes[attribute];
          }
        }
        var s = document.createElement('script');
        s.setAttribute('src', 'https://giscus.app/client.js');
        s.setAttribute('crossorigin', 'anonymous');
        for (let attribute in attributes) {
          s.setAttribute(attribute, attributes[attribute]);
        }
        var ss = document.getElementsByTagName('script');
        var e = ss.length > 0 ? ss[ss.length - 1] : document.head || document.documentElement;
        e.parentNode.insertBefore(s, e.nextSibling);
      });
    </script>
    <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  <div>
    <span id="timeDate">正在载入天数...</span>
    <span id="times">载入时分秒...</span>
    <script>
    var now = new Date();
    function createtime(){
        var grt= new Date("03/08/2025 00:00:00");
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24;
        dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum);
        hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){
            hnum = "0" + hnum;
        }
        minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes);
        if(String(mnum).length ==1 ){
                  mnum = "0" + mnum;
        }
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds);
        if(String(snum).length ==1 ){
                  snum = "0" + snum;
        }
        document.getElementById("timeDate").innerHTML = "🚀已持续航行&nbsp"+dnum+"&nbsp天";  
        document.getElementById("times").innerHTML = hnum + "&nbsp时&nbsp" + mnum + "&nbsp分&nbsp" + snum + "&nbsp秒";
    }
    setInterval("createtime()",250);
    </script>
  </div>

  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
